# BrainstormGPT üß†‚õàÔ∏è
BrainstormGPT creates two ChatGPT instances and tasks them to work together to solve a problem. Lastly, a synthesis of the proposed solution is created and an HTML file of the synthesis is created which can be easily exported to a PDF.

## Example (GPT-3.5)
`Problem: Hospital acquired infections are a significant source of mortality and morbidity.`

**Initial solution:**
  
Implement strict infection control protocols in hospitals, such as hand hygiene, use of personal protective equipment, and proper cleaning and disinfection of surfaces and medical equipment. Increase education and training for healthcare workers on infection control measures. Utilize technology, such as electronic monitoring systems and antimicrobial coatings, to further reduce the spread of infections. Regularly monitor and report infection rates to identify areas for improvement. Collaborate with other healthcare facilities and public health agencies to share best practices and coordinate efforts in infection control.

**Brainstormed solution**:

[Link to Generated Report](example.pdf)

[Full conversation between agents](conversation.txt)

## Motivation
The first solution generated by ChatGPT is usually pretty good, but humans often have to iterate back-and-forth with ChatGPT to refine the output further. Why not automate this back-and-forth by having two ChatGPT instances talk to each other?

## Methodology
First, the user inputs a problem statement and any additional information they'd like to provide. Optionally, a user can input a seed solution to the problem if they've thought of something already. If no seed is provided, then ChatGPT is prompted to generate a seed solution to the problem. This seed solution is then given to a ChatGPT instance that is instructed to critically analyze the solution proposed, find flaws, and suggest improvements. The chat history, in addition to the most recently generated response, is fed back into ChatGPT with the same system prompt, but with the `user` and `assistant` roles flipped for each message. This process can be repeated indefinitely until the models run out of context length (though often they end up concluding early and simply repeating to themselves that they've made great progress).

Then, the chat history is given to another ChatGPT instance, which is instructed to read through the conversation and synthesize a final proposal from the conversation history. Lastly, the proposal is once again given to ChatGPT, which stylizes the proposal in HTML, after which the user can read through the report in a web browser and/or save it as a PDF.

## Usage/requirements
Reqs:
`pip install openai tiktoken`

Usage:
`python main.py --temp [temperature] --top_p [top_p] --engine [gpt-3.5-turbo or gpt-4 (recommended)] --max_len [max number of tokens for the conversation]`

## Drawbacks and Future Work
GPT-3.5 tends to agree with itself relentlessly, though it does sometimes still offer suggestions after agreeing. GPT-4 is better at this, but token counts and costs add up pretty quickly.

This feels mostly like a prompt-engineering challenge, and I think that creating better prompts than the ones I wrote in a couple of minutes could improve the quality of generations.

Regardless, I really look forward to a future where we can give capable models problems we need to brainstorm solutions for and have them rapidly iterate and propose solutions that may have taken us humans a while to come up with!
